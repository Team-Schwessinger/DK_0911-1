{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to get synteny measures between two assemblies\n",
    "The goal is to get a tool that takes in orthofinder results and a CDS files to check fof the length of synteny with different gene categories.\n",
    "\n",
    "The idea is that BUSCOs are more syntenous then effectors or such. \n",
    "\n",
    "The program tries to count how many neighbours of an allele pair are in the same orthogroup. This requires first to anchor the allele pairing e.g. find out what the 1:1 allele is and then walk outward to see if each others neighbours are in the same orthogroup. We can run this simple without allowing for skips and in simple=Flase mode to allow for a skip by one.\n",
    "\n",
    "GENOMEA_orthoarray =  [1,2,3,4]\n",
    "GENOMEB_orthoarray =  [1,2,3,5]\n",
    "\n",
    "The result of a comparison is an array of length n where n is the size of the tested synteny block. The initial outcome is an array of length n where 1 represents a orthology mathch, where 0 represents not an orthology match and where np.nan represents the lack of test for orthology match (e.g. where one of the genes is at the edge of a contig). These arrays can be converted in tuples, where the first is number of observed matches (sum of 1s) and where the second value is the number of possible values (0 and 1 == non np.nan in the array).  \n",
    "For the case above the match array for n = 5 should be [1,1,1,0,nan] and the tuple (3,4)\n",
    "\n",
    "If this analysis is performed on two different set of gene groups this may tell something if microsynteny is more conserved within one gene group then another. Also have a look at http://chibba.pgml.uga.edu/mcscan2/ for synteny analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initial outline\n",
    "\n",
    "get a gene ID -> get its neightbours n in two different arrays up and down stream -> get the orthogroup arrays for the neighbours \n",
    "get a gene ID  -> get orthogroup of the gene -> get all members of the orthogroup that belong to the other genome -> get their neighbours +/- 1 -> get the best seed where both neighbours add up,  \n",
    "* if we have only one best match that is easy. Use this seed as 1:1 match get the neighbourhood array up and down -> compare the arrays one element at a time and safe the match_up and match_down dictionray.\n",
    "* if multiple hits. Move one further out with each hit and look at those with the same ideas.\n",
    "\n",
    "Things also to generate:\n",
    "A match dictionary for allele pairing.  \n",
    "A unqiue gene dictionary.  \n",
    "A paraloge dictionray. Meaning where there is no allele pairing but thing are in the same ortho group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:56:20.618668Z",
     "start_time": "2019-03-12T05:56:20.564911Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio import SeqUtils\n",
    "import pysam\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from pybedtools import BedTool\n",
    "import numpy as np\n",
    "import pybedtools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "from Bio.Seq import Seq\n",
    "import pysam\n",
    "from Bio import SearchIO\n",
    "import json\n",
    "import glob\n",
    "import scipy.stats as stats\n",
    "import statsmodels as sms\n",
    "import statsmodels.sandbox.stats.multicomp\n",
    "import distance\n",
    "import seaborn as sns\n",
    "from pybedtools import BedTool\n",
    "import matplotlib\n",
    "from sklearn.externals.joblib import Parallel, delayed\n",
    "import itertools as it\n",
    "import tempfile\n",
    "from scipy.signal import argrelextrema\n",
    "import scipy\n",
    "from IPython.display import Image\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "###on the command line\n",
    "cat Orthogroups_3.csv Orthogroups_3_UnassignedGenes.csv > Orthogroups_3_combined.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:45:25.807189Z",
     "start_time": "2019-03-12T05:45:25.794587Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### define some path that at the end should come as args\n",
    "ORTHOFINDER_FILE_NAME = '/home/benjamin/genome_assembly/Warrior/DK0911_v04/comp_orthology/orthofinder/result_update_redundant_protein_sets_01032019/Orthogroups_3_combined.csv'\n",
    "QUERY_GENOME_GENE_BED6 = '/home/benjamin/genome_assembly/Warrior/DK0911_v04/comp_orthology/Pst104E_annotations/Pst_104E_v13_ph_ctg.gene.bed'\n",
    "SUBJECT_GENOME_GENE_BED6 = '/home/benjamin/genome_assembly/Warrior/DK0911_v04/comp_orthology/DK0911_annotations/DK_0911_v04_ph_ctg.genes.gene.bed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:54:22.591657Z",
     "start_time": "2019-03-12T05:54:22.582688Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUT_PATH = '/home/benjamin/genome_assembly/Warrior/DK0911_v04/comp_orthology/orthofinder/Ps104E_v13_vs_DK0911'\n",
    "if not os.path.exists(OUT_PATH):\n",
    "    os.mkdir(OUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:45:52.414834Z",
     "start_time": "2019-03-12T05:45:52.308900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now write some functions\n",
    "def get_neighbours(gene_id, bed_filename, n=5, direction='up'):\n",
    "    \"\"\"A function that either takes a filename to return an array of downstream and upstream neighbouring genes.\n",
    "    Input: \n",
    "        gene_id\n",
    "        bed6 filename\n",
    "        n being the number of neighbours we want to get\n",
    "        direction being up or down.\n",
    "    Output:\n",
    "        returns the largest possible array of neighbours up to n.\n",
    "        The 0 element is always the closest neighbour no matter if you return and 'up' or 'down' array.\"\"\"\n",
    "    bed_6_header = ['chrom', 'start', 'stop', 'gene_id', 'phase', 'strand']\n",
    "    try:\n",
    "        bed_df = pd.read_csv(bed_filename, sep='\\t', header=None, names=bed_6_header)\n",
    "    except:\n",
    "        print('Check if the bedfiles are bed6')\n",
    "    if not direction in ['up', 'down']:\n",
    "        print('Ensure direction is up or down.')\n",
    "        \n",
    "    #fix to make sure the gene id is actually in the bed_file if not just return an empty list    \n",
    "    if gene_id not in bed_df['gene_id'].unique():\n",
    "        print('Warning gene %s is not in bed file!' % gene_id)\n",
    "        return []\n",
    "    gene_index = bed_df[bed_df['gene_id'] == gene_id].index[0]\n",
    "    contig = bed_df.loc[gene_index, ['chrom']]['chrom']\n",
    "    contig_index = bed_df[bed_df['chrom']== contig].index\n",
    "    if direction == 'up':\n",
    "        index_list = []\n",
    "        if (gene_index+(n)) in contig_index:\n",
    "            for i in range(gene_index+1, gene_index+(n+1)):\n",
    "                index_list.append(i)\n",
    "        else:\n",
    "            for i in range(gene_index+1, contig_index[-1]+1):\n",
    "                index_list.append(i)\n",
    "        return bed_df.loc[index_list, ['gene_id']]['gene_id'].tolist()\n",
    "    if direction == 'down':\n",
    "        index_list = []\n",
    "        if (gene_index-n) in contig_index:\n",
    "            for i in range(gene_index-(n), gene_index):\n",
    "                index_list.append(i)\n",
    "        else:\n",
    "            for i in range(contig_index[0], gene_index):\n",
    "                index_list.append(i)\n",
    "        index_list.reverse()\n",
    "        return bed_df.loc[index_list, ['gene_id']]['gene_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:45:53.445309Z",
     "start_time": "2019-03-12T05:45:53.408430Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ortho_dict(file_name):\n",
    "    \"\"\"Function that takes a orthofinder file name and generates an orthofinder dict.\n",
    "    Input:\n",
    "        CSV Filename of orthofinder output.\n",
    "    Output:\n",
    "        Orthofinder dict with keys intergers of the numerical part of the orthofinder group.\n",
    "        Values are the gene identifier of each orthogroup.\"\"\"\n",
    "    orthofinder_dict = {}\n",
    "    try:\n",
    "        with open(file_name) as fh:\n",
    "            for line in fh:\n",
    "                if line.startswith('OG'):\n",
    "                    line.strip()\n",
    "                    OG = line.split('\\t')[0]\n",
    "                    value = [x.strip() for x in line.split(OG)[1].replace('\\t',',').split(',') if x != '']\n",
    "                    orthofinder_dict[int(line.split('\\t')[0].strip('OG'))] = value\n",
    "        return orthofinder_dict\n",
    "    except FileNotFoundError:\n",
    "        print(\"Please check the orthofinder in put file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:45:54.657085Z",
     "start_time": "2019-03-12T05:45:54.645654Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gene_to_ortho_dict(orthofinder_dict):\n",
    "    \"\"\"Function that makes a gene to ortho dict.\"\"\"\n",
    "    gene_to_ortho_dict = {}\n",
    "    for key,value in orthofinder_dict.items():\n",
    "        for item in value:\n",
    "            gene_to_ortho_dict[item] = key\n",
    "    return gene_to_ortho_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:45:55.053301Z",
     "start_time": "2019-03-12T05:45:55.036147Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_orthologs(gene_id, gene_to_ortho_dict, orthofinder_dict, other_id):\n",
    "    \"\"\"The function returns all the potential orthologs of the comparative species\n",
    "    Input:\n",
    "        gene_id\n",
    "        gene_to_ortho_dict, the ortho dict\n",
    "        orthofinder_dict, the dictionary of the orthgroups to get all genes belonging to the orthogroup in question.\n",
    "        other_id, is the identifier of the comparative species.\"\"\"\n",
    "\n",
    "    return [x for x in orthofinder_dict[gene_to_ortho_dict[gene_id]] if x.startswith(other_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:45:55.838512Z",
     "start_time": "2019-03-12T05:45:55.702105Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_pairings_array(query_ortho, subject_ortho, n=5, simple = False):\n",
    "    \"\"\"Function that does a pairwise by element comparison of two arrays.\n",
    "    In the simple = True mode this is a stricked 1:1 pairing.\n",
    "    In the simple = Flase mode this is a sliding window of 1 either way. E.g. position query 1 is compared\n",
    "    to position subject 0, 1 and 2.\n",
    "    Input: \n",
    "        query_ortho list\n",
    "        subject_orth list\n",
    "        n is the length of the comparison to be made.\n",
    "        simple True or False, default is Flase allowing for skiping of 1.\n",
    "    output:\n",
    "        result array that has the positional overlap of the array.\n",
    "        e.g. for n = 8 with one list being length 8 and the other length 6\n",
    "        [0, 1, 0, 1, 0, 1, nan, nan]\"\"\"\n",
    "    \n",
    "    array = np.empty(n)\n",
    "    array[:] = np.nan\n",
    "    array\n",
    "    \n",
    "    if simple == True:\n",
    "        #this is a simple 1:1 comparison for the two arrays.\n",
    "        #comparison is only possible till the shortest list is done.\n",
    "        for i in range(0, n):\n",
    "            if i < len(query_ortho) and i < len(subject_ortho):\n",
    "                if query_ortho[i] == subject_ortho[i]:\n",
    "                    array[i] = int(1)\n",
    "                else:\n",
    "                    array[i] = int(0)\n",
    "            else:\n",
    "                continue\n",
    "        return array\n",
    "            \n",
    "        \n",
    "    if simple == False:\n",
    "        #do a three point comparison when possible else do whats possible.\n",
    "        #retunr the array\n",
    "        for i in range(0, len(query_ortho)):\n",
    "            \n",
    "            if i == len(subject_ortho)-1:\n",
    "                if query_ortho[i] == subject_ortho[i-1] or query_ortho[i] == subject_ortho[i]:\n",
    "                    array[i] = int(1)\n",
    "                else:\n",
    "                    array[i] = int(0)\n",
    "            elif i > 0 and i < len(subject_ortho):    \n",
    "                if query_ortho[i] == subject_ortho[i] or query_ortho[i] == subject_ortho[i-1] \\\n",
    "                or query_ortho[i] == subject_ortho[i+1]:\n",
    "                    array[i] = int(1)\n",
    "                else:\n",
    "                    array[i] = int(0)\n",
    "\n",
    "            elif i == 0:\n",
    "                do_it = False\n",
    "                try:\n",
    "                    if query_ortho[i] == subject_ortho[i+1]:\n",
    "                        do_it = True\n",
    "                except IndexError:\n",
    "                        pass\n",
    "                try:\n",
    "                    if query_ortho[i] == subject_ortho[i]:\n",
    "                        do_it = True\n",
    "                except IndexError:\n",
    "                        pass\n",
    "                if do_it == True:\n",
    "                    array[i] = int(1)\n",
    "                else:\n",
    "                    array[i] = int(0)\n",
    "        return array\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:49:26.885782Z",
     "start_time": "2019-03-12T05:49:26.082638Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_up_and_down_array(gene_id, query_downstream_ortho,query_upstream_ortho, subject_bed_fn, n, simple):\n",
    "    ### TO-DO think about adding control on how to initially find pairings 0-0 and how to do the counting\n",
    "    ### of matches later.\n",
    "    \n",
    "    \"\"\"A function that returns a list two arrays. The first array is the for the downstream pairing the second for the\n",
    "    upstream pairing 1 being a match, 0 being no match, nan being no match possible.\n",
    "    Input: \n",
    "           Gene_id to check from the subject genome, e.g. initial orthogroup matches of query gene.\n",
    "           query_downstream_ortho is the list of downstream ortho groups from the gene_ids neighbours.\n",
    "           query_upstream_ortho is the list of upstream ortho groups from the gene_ids neighbours.\n",
    "           subject_bed_fn is the absolute path of the subject_bed_fn to get the neighbouring genes of the gene_id.\n",
    "           n is the numbers of neighbours to search.\n",
    "           simple can be True or False for searching without skiping (window of three) or with skipping enabled.\n",
    "    Output:\n",
    "           [down_array,up_array]\"\"\"\n",
    "    \n",
    "    \n",
    "    if simple not in [True, False]:\n",
    "        simple = False\n",
    "    \n",
    "    #get the ortho dictionaries for the gene_id which is an ortho hit of the query.\n",
    "    subject_upstream_ortho = [gene_to_ortho_dict[x] for x \\\n",
    "                              in get_neighbours(gene_id, subject_bed_fn, n=n, direction='up')]\n",
    "    subject_downstream_ortho = [gene_to_ortho_dict[x] for x \\\n",
    "                                in get_neighbours(gene_id, subject_bed_fn, n=n, direction='down')]\n",
    "    \n",
    "    #now move to empty arrays\n",
    "    \n",
    "    \n",
    "    #define in case something has no upstream or downstream hits\n",
    "    array = array = np.empty(n)\n",
    "    array[:] = np.nan\n",
    "    up_array, down_array = array, array\n",
    "    \n",
    "    if simple == True:\n",
    "        \n",
    "        if len(query_upstream_ortho) > 0 and len(subject_upstream_ortho) > 0: \n",
    "        #check the upstream upstream matching and ask if 0 in subject is 0 in the query  \n",
    "        #TO-DO check if we maybe want to do 0, 1 subject == 0 as well.\n",
    "            if query_upstream_ortho[0] == subject_upstream_ortho[0]:   \n",
    "                up_array = count_pairings_array(query_upstream_ortho, subject_upstream_ortho, n, simple=simple)       \n",
    "                #now look at the downstream\n",
    "                down_array = count_pairings_array(query_downstream_ortho, subject_downstream_ortho,n, simple=simple)\n",
    "\n",
    "                if len(query_downstream_ortho) > 0:\n",
    "                    if query_downstream_ortho[0] == subject_upstream_ortho[0]:\n",
    "                        print(\"Orthogroups of up and downstream are the same. Gene_id: %s\" % gene_id)\n",
    "                        up_array_new = count_pairings_array(query_upstream_ortho, subject_downstream_ortho, n, simple=simple)\n",
    "                        down_array_new = count_pairings_array(query_downstream_ortho, subject_upstream_ortho, n, simple=simple)\n",
    "                        #this compares if the one has more pairing then the other combination of possible \n",
    "                        #neighboorhood match arrays\n",
    "                        if up_down_ratio_array([down_array_new, up_array_new])\\\n",
    "                                > up_down_ratio_array([down_array, up_array]):\n",
    "                                #think about if we also want to test for \n",
    "                                #(max_down_new+max_up_new) > (max_down, max_up) :\n",
    "                            down_array, up_array = down_array_new, up_array_new\n",
    "                        #break the stallmate by assiningn randomly\n",
    "                        elif up_down_ratio_array([down_array_new, up_array_new])\\\n",
    "                                == up_down_ratio_array([down_array, up_array])\\\n",
    "                                and((np.random.random() < 0.5)):\n",
    "                            down_array, up_array = down_array_new, up_array_new\n",
    "\n",
    "\n",
    "                return [down_array, up_array]\n",
    "\n",
    "        if len(query_upstream_ortho) >0 and len(subject_downstream_ortho) > 0:\n",
    "            \n",
    "            if query_upstream_ortho[0] == subject_downstream_ortho[0]:\n",
    "                up_array = count_pairings_array(query_upstream_ortho, subject_downstream_ortho, n, simple=simple)\n",
    "                down_array = count_pairings_array(query_downstream_ortho, subject_upstream_ortho, n, simple=simple)\n",
    "                return [down_array, up_array]\n",
    "\n",
    "        if len(query_downstream_ortho) > 0 and len(subject_downstream_ortho) > 0: \n",
    "            if subject_downstream_ortho[0] == query_downstream_ortho[0]:\n",
    "                up_array = count_pairings_array(query_upstream_ortho, subject_upstream_ortho,n, simple=simple)       \n",
    "                #now look at the downstream\n",
    "                down_array = count_pairings_array(query_downstream_ortho, subject_downstream_ortho,n, simple=simple)\n",
    "                return [down_array, up_array]\n",
    "\n",
    "        return [down_array, up_array]\n",
    "    \n",
    "    elif simple == False:\n",
    "        \n",
    "        do_it = False\n",
    "        one_exists = False\n",
    "        ###To-Do this still needs to be fixed to check if also the downstream match\n",
    "        ###Right now this generates a bias in the analysis that the +1 position is more common the -1\n",
    "        if len(query_upstream_ortho) > 0 and len(subject_upstream_ortho) > 0: \n",
    "            try:\n",
    "                if query_upstream_ortho[0] == subject_upstream_ortho[0] or \\\n",
    "                query_upstream_ortho[0] == subject_upstream_ortho[1]:\n",
    "                    do_it = True\n",
    "            \n",
    "            except IndexError:\n",
    "                if query_upstream_ortho[0] == subject_upstream_ortho[0]:\n",
    "                    do_it = True\n",
    "                    \n",
    "            if do_it == True:        \n",
    "                up_array = count_pairings_array(query_upstream_ortho, subject_upstream_ortho, n, simple=simple)       \n",
    "                #now look at the downstream\n",
    "                down_array = count_pairings_array(query_downstream_ortho, subject_downstream_ortho,n, simple=simple)\n",
    "\n",
    "                if len(query_downstream_ortho) > 0 and len(subject_upstream_ortho) > 0:\n",
    "                    do_it_too = False\n",
    "                    try:\n",
    "                        if query_downstream_ortho[0] == subject_upstream_ortho[0] or \\\n",
    "                        query_downstream_ortho[0] == subject_upstream_ortho[1]:\n",
    "                            do_it_too = True\n",
    "                    except IndexError:\n",
    "                        if query_downstream_ortho[0] == subject_upstream_ortho[0]:\n",
    "                            do_it_too = True\n",
    "                            \n",
    "                        if do_it_too == True:\n",
    "                            #print(\"Orthogroups of up and downstream are the same. Gene_id: %s\" % gene_id)\n",
    "                            up_array_new = count_pairings_array(query_upstream_ortho, subject_downstream_ortho, n, simple=simple)\n",
    "                            down_array_new = count_pairings_array(query_downstream_ortho, subject_upstream_ortho, n, simple=simple)\n",
    "                            if up_down_ratio_array([down_array_new, up_array_new])\\\n",
    "                                > up_down_ratio_array([down_array, up_array]):\n",
    "                                #think about if we also want to test for \n",
    "                                #(max_down_new+max_up_new) > (max_down, max_up) :\n",
    "                                down_array, up_array = down_array_new, up_array_new\n",
    "                            elif up_down_ratio_array([down_array_new, up_array_new])\\\n",
    "                                == up_down_ratio_array([down_array, up_array])\\\n",
    "                                and((np.random.random() < 0.5)):\n",
    "                                down_array, up_array = down_array_new, up_array_new\n",
    "\n",
    "\n",
    "                    return [down_array, up_array]\n",
    "\n",
    "        if len(query_upstream_ortho) >0 and len(subject_downstream_ortho) > 0:\n",
    "            try:\n",
    "                \n",
    "                if query_upstream_ortho[0] == subject_downstream_ortho[0] or \\\n",
    "                query_upstream_ortho[0] == subject_downstream_ortho[1]:\n",
    "                    do_it = True\n",
    "            except IndexError:\n",
    "                if query_upstream_ortho[0] == subject_downstream_ortho[0]:\n",
    "                    do_it = True\n",
    "            if do_it == True:\n",
    "                up_array = count_pairings_array(query_upstream_ortho, subject_downstream_ortho, n, simple=simple)\n",
    "                down_array = count_pairings_array(query_downstream_ortho, subject_upstream_ortho, n, simple=simple)\n",
    "                return [down_array, up_array]\n",
    "\n",
    "        if len(query_downstream_ortho) > 0 and len(subject_downstream_ortho) > 0:\n",
    "            try: \n",
    "                if subject_downstream_ortho[0] == query_downstream_ortho[0] or \\\n",
    "                subject_downstream_ortho[0] == query_downstream_ortho[1]:\n",
    "                    do_it = True\n",
    "            except IndexError:\n",
    "                if subject_downstream_ortho[0] == query_downstream_ortho[0]:\n",
    "                    do_it = True\n",
    "            if do_it == True:\n",
    "                up_array = count_pairings_array(query_upstream_ortho, subject_upstream_ortho,n, simple=simple)       \n",
    "                    #now look at the downstream\n",
    "                down_array = count_pairings_array(query_downstream_ortho, subject_downstream_ortho,n, simple=simple)\n",
    "                return [down_array, up_array]\n",
    "\n",
    "        return [down_array, up_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:49:35.549267Z",
     "start_time": "2019-03-12T05:49:35.536644Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def array_to_tuple(array_list):\n",
    "    \"\"\"Converts arrays to (obs, max_poss_obs) tuples ignoring nans.\"\"\"\n",
    "    if len(array_list) != 2:\n",
    "        print('The length of the list is not 2.')\n",
    "        return 0\n",
    "    tuple_list = []\n",
    "    for array in array_list:\n",
    "        tuple_list.append(((np.nan_to_num(array)).sum(),np.count_nonzero(~np.isnan(array)) ))\n",
    "    return tuple_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:49:36.041340Z",
     "start_time": "2019-03-12T05:49:36.026823Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def up_down_ratio_array(up_down_list):\n",
    "    \"\"\"Returns the ratio of observed matches over possible matches of both down and up array together.\"\"\"\n",
    "    if len(up_down_list) != 2:\n",
    "        print('The length of the list is not 2.')\n",
    "        return 0\n",
    "    sum_observed = np.nan_to_num(up_down_list[0]).sum() + np.nan_to_num(up_down_list[1]).sum()\n",
    "    sum_possible = np.count_nonzero(~np.isnan(up_down_list[0])) + np.count_nonzero(~np.isnan(up_down_list[1]))\n",
    "    if sum_possible > 0:\n",
    "        \n",
    "        return sum_observed/sum_possible\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:49:36.541602Z",
     "start_time": "2019-03-12T05:49:36.514634Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def up_down_ratio(up_down_list):\n",
    "    \"\"\"Up down ratio for tuples (obs, max_poss_obs).\"\"\"\n",
    "    if len(up_down_list) == 0:\n",
    "        return 0\n",
    "    if (up_down_list[0][1] + up_down_list[1][1]) > 0:\n",
    "        ratio = (up_down_list[0][0] + up_down_list[1][0]) / (up_down_list[0][1] + up_down_list[1][1])\n",
    "        return ratio\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:49:37.114196Z",
     "start_time": "2019-03-12T05:49:37.099092Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate dicts that will be used to track things\n",
    "allele_dict = {}\n",
    "singleton_dict = {}\n",
    "paralog_dict = {}\n",
    "up_match_dict = {}\n",
    "down_match_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:49:39.164209Z",
     "start_time": "2019-03-12T05:49:39.022205Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the identifiers if not provided.\n",
    "query_id = pd.read_csv(QUERY_GENOME_GENE_BED6, sep='\\t', header=None).loc[0,[3]][3].split('_')[0]\n",
    "subject_id = pd.read_csv(SUBJECT_GENOME_GENE_BED6, sep='\\t', header=None).loc[0,[3]][3].split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:49:42.109326Z",
     "start_time": "2019-03-12T05:49:40.062252Z"
    }
   },
   "outputs": [],
   "source": [
    "#get the orthofinder results read in\n",
    "#this is the dict for all orthogroups and what members they have\n",
    "orthofinder_dict = get_ortho_dict(ORTHOFINDER_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:49:43.360228Z",
     "start_time": "2019-03-12T05:49:42.650598Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is the dict for proteins and what orthogroup they have\n",
    "gene_to_ortho_dict = get_gene_to_ortho_dict(orthofinder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:49:44.092483Z",
     "start_time": "2019-03-12T05:49:44.014658Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_genes = pd.read_csv(SUBJECT_GENOME_GENE_BED6, sep='\\t', header=None)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-12T05:49:44.666477Z",
     "start_time": "2019-03-12T05:49:44.634634Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check whats in the input orthofile and what's missing\n",
    "for gene in query_genes:\n",
    "    try:\n",
    "        gene_to_ortho_dict[gene]\n",
    "    except:\n",
    "        print(gene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-13T04:50:35.847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3.0, 3), (4.0, 8)]\n",
      "Done comparing!\n",
      "[(4.0, 4), (3.0, 8)]\n",
      "[(0.0, 1), (6.0, 8)]\n",
      "Done comparing!\n",
      "[(5.0, 5), (2.0, 8)]\n",
      "[(1.0, 1), (5.0, 7)]\n",
      "Done comparing!\n",
      "Done comparing!\n",
      "[(5.0, 7), (1.0, 8)]\n",
      "[(1.0, 3), (5.0, 5)]\n",
      "Done comparing!\n",
      "[(6.0, 8), (0.0, 8)]\n",
      "[(2.0, 4), (4.0, 4)]\n",
      "Done comparing!\n",
      "[(3.0, 5), (3.0, 3)]\n",
      "Done comparing!\n",
      "[(1.0, 8), (6.0, 8)]\n",
      "[(4.0, 6), (2.0, 2)]\n",
      "Done comparing!\n",
      "[(2.0, 8), (5.0, 8)]\n",
      "[(5.0, 7), (1.0, 1)]\n",
      "Done comparing!\n",
      "[(2.0, 8), (4.0, 8)]\n",
      "[(3.0, 8), (4.0, 8)]\n",
      "[(4.0, 7), (0.0, 1)]\n",
      "[(6.0, 8), (0.0, 1)]\n",
      "Done comparing!\n",
      "[(4.0, 8), (3.0, 8)]\n",
      "Done comparing!\n",
      "[(6.0, 8), (1.0, 8)]\n",
      "Done comparing!\n",
      "[(7.0, 8), (0.0, 8)]\n",
      "Done comparing!\n",
      "Done comparing!\n",
      "[(0.0, 1), (7.0, 8)]\n",
      "Done comparing!\n"
     ]
    }
   ],
   "source": [
    "#generate dicts that will be used to track things\n",
    "allele_dict = {}\n",
    "singleton_dict = {}\n",
    "paralog_dict = {}\n",
    "up_match_dict = {}\n",
    "down_match_dict = {}\n",
    "n=8\n",
    "simple = False\n",
    "#testing set loop\n",
    "gene_done_list = []\n",
    "df = pd.read_csv(QUERY_GENOME_GENE_BED6, sep='\\t', header=None)\n",
    "for gene_id in df[3].tolist():\n",
    "    gene_done_list.append(gene_id)\n",
    "    #now some testing here    \n",
    "    query_upstream = get_neighbours(gene_id, QUERY_GENOME_GENE_BED6, n=n, direction='up')\n",
    "    query_downstream = get_neighbours(gene_id, QUERY_GENOME_GENE_BED6, n=n, direction='down')\n",
    "    query_upstream_ortho = [gene_to_ortho_dict[x] for x in query_upstream]\n",
    "    query_downstream_ortho = [gene_to_ortho_dict[x] for x in query_downstream]\n",
    "    \n",
    "    first_orthologs = get_orthologs(gene_id, gene_to_ortho_dict, orthofinder_dict, subject_id)\n",
    "    if len(first_orthologs) == 0:\n",
    "        #if we don't have an ortho hit put it in the singleton dict\n",
    "        singleton_dict[gene_id] = True\n",
    "    elif len(first_orthologs) == 1:\n",
    "        down_up_list = get_up_and_down_array(first_orthologs[0],\\\n",
    "                            query_downstream_ortho,query_upstream_ortho, SUBJECT_GENOME_GENE_BED6,\\\n",
    "                                             n=n, simple=simple)\n",
    "        down_match_dict[gene_id], up_match_dict[gene_id] = down_up_list[0], down_up_list[1]\n",
    "        \n",
    "        #this here defines \"alleles\". Alleles are genes where the immediate neighbour is conserved.\n",
    "        #consider simple True/False here.\n",
    "        try:\n",
    "            if down_up_list[0][0] == 1 and down_up_list[1][0] == 1:\n",
    "                allele_dict[gene_id] = first_orthologs[0]\n",
    "            else:\n",
    "                paralog_dict[gene_id] = first_orthologs[0]\n",
    "        except IndexError:\n",
    "                paralog_dict[gene_id] = first_orthologs[0]\n",
    "    \n",
    "    elif len(first_orthologs) > 1:\n",
    "        #generate a potential ortho_dict that stores the options\n",
    "        #afterwards we loop over the option and see what is best.\n",
    "        ortho_dict = {}\n",
    "        for ortho in first_orthologs:\n",
    "            down_up_list = get_up_and_down_array(ortho,query_downstream_ortho,query_upstream_ortho,\\\n",
    "                                               SUBJECT_GENOME_GENE_BED6, n=n, simple=simple)\n",
    "            #TO-DO check for edge cases here\n",
    "            if sum((~np.isnan(down_up_list[0]))) == 0 and sum((~np.isnan(down_up_list[1]))) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                ortho_dict[ortho] = down_up_list\n",
    "\n",
    "        array = array = np.empty(n)\n",
    "        array[:] = np.nan\n",
    "        max_list = [(0,0), (0,0)]\n",
    "        real_ortho = ''\n",
    "        real_ortho_list = [array, array]\n",
    "        \n",
    "        #this loop intentifies the best ortho hit. If two get the best score\n",
    "        #the first one is kept. has a change element.\n",
    "        #TO-DO consider how splits are handled better.\n",
    "        for ortho, ortho_list in ortho_dict.items():\n",
    "            ortho_tuple_list = array_to_tuple(ortho_list)\n",
    "            #fix the issue with always staying on the state when equal\n",
    "            if (up_down_ratio(ortho_tuple_list) == up_down_ratio(max_list)) \\\n",
    "            and (np.random.random() < 0.5):\n",
    "                max_list = ortho_tuple_list\n",
    "                real_ortho = ortho\n",
    "                real_ortho_list = ortho_list\n",
    "                \n",
    "            elif up_down_ratio(ortho_tuple_list) > up_down_ratio(max_list):\n",
    "                print(ortho_tuple_list)\n",
    "                max_list = ortho_tuple_list\n",
    "                real_ortho = ortho\n",
    "                real_ortho_list = ortho_list\n",
    "        \n",
    "\n",
    "        down_match_dict[gene_id], up_match_dict[gene_id] = real_ortho_list[0], real_ortho_list[1]\n",
    "        \n",
    "        #this is how alleles and paralogs are defined.\n",
    "        #TO-DO consider if paralogs should be treated differently then simply assiging all in the\n",
    "        #ortho dict\n",
    "        \n",
    "        if ortho_dict == {}:\n",
    "            paralog_dict[gene_id] = first_orthologs\n",
    "        else:\n",
    "        \n",
    "            paralog_dict[gene_id] = list(ortho_dict.keys())\n",
    "\n",
    "            try:\n",
    "                if real_ortho_list[0][0] == 1 and real_ortho_list[1][0] == 1:\n",
    "                    allele_dict[gene_id] = real_ortho\n",
    "                else:\n",
    "                    paralog_dict[gene_id] = list(ortho_dict.keys())\n",
    "            except IndexError:\n",
    "                paralog_dict[gene_id] = list(ortho_dict.keys())\n",
    "        print('Done comparing!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-13T04:50:36.991Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "down_match_df = pd.DataFrame.from_dict(down_match_dict).T\n",
    "up_match_df = pd.DataFrame.from_dict(up_match_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-13T04:50:37.872Z"
    }
   },
   "outputs": [],
   "source": [
    "#save it out \n",
    "#d = date.today().strftime(\"%y%m%d\")\n",
    "name = OUT_PATH.split('/')[-1]\n",
    "up_match_df.to_csv(os.path.join(OUT_PATH, ('%s_%s_up_match_simple_true_df.csv' % (d, name))))\n",
    "down_match_df.to_csv(os.path.join(OUT_PATH, ('%s_%s_down_match_simple_true_df.csv'% (d, name))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-13T04:50:38.647Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_to_df(new_dict, path, date, name):\n",
    "    \"\"\"Saves one of the generate dicts as dataframe.\n",
    "    INPUT:\n",
    "        dict\n",
    "        path\n",
    "        data\n",
    "        name\"\"\"\n",
    "    df = pd.DataFrame.from_dict(new_dict, orient='index')\n",
    "    df['Query'] = df.index\n",
    "    df.rename(columns={0: 'Target'}, inplace = True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.loc[:, ['Query', 'Target']].to_csv(os.path.join(path, ('%s_%s.csv')% (date, name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-13T04:50:39.623Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_to_df(allele_dict, OUT_PATH, d, '%s_allele' % name)\n",
    "dict_to_df(singleton_dict, OUT_PATH, d, '%s_singleton' %name)\n",
    "dict_to_df(paralog_dict, OUT_PATH, d, '%s_paraloge' %name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-13T04:50:40.335Z"
    }
   },
   "outputs": [],
   "source": [
    "allele_df = pd.DataFrame.from_dict(allele_dict, orient='index')\n",
    "allele_df['Query'] = allele_df.index\n",
    "allele_df.rename(columns={0: 'Target'}, inplace = True)\n",
    "allele_df.reset_index(drop=True, inplace=True)\n",
    "allele_df.loc[:, ['Query', 'Target']].to_csv(os.path.join(OUT_PATH, ('%s_%s_allele.csv')% (d, name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-13T04:50:43.442Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(paralog_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
